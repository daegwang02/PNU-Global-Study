import json
import datetime
from html_scraper import scrape_saramin, scrape_incruit, scrape_jobkorea, scrape_wevity, scrape_campuspick

DATA_FILE = "data.json"

def load_data():
    try:
        with open(DATA_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {"lastUpdated": None, "jobs": [], "contests": []}

def save_data(data):
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def main():
    print("==================================================")
    print("ğŸ“¡ HTML ê¸°ë°˜ ìŠ¤í¬ë˜í•‘ ì‹œì‘!")

    data = load_data()

    all_jobs = []
    all_contests = []

    # ğŸ§¹ ê¸°ì¡´ ë°ì´í„° ì œê±° (í•­ìƒ ìµœì‹  ëª©ë¡ìœ¼ë¡œ ìœ ì§€)
    print("ğŸ§¹ ê¸°ì¡´ ë°ì´í„° ì´ˆê¸°í™”")

    # ğŸ“Œ ê° ì‚¬ì´íŠ¸ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
    print("ğŸ” ì‚¬ëŒì¸ ì±„ìš© ìˆ˜ì§‘ ì¤‘...")
    all_jobs += scrape_saramin()

    print("ğŸ” ì¸í¬ë£¨íŠ¸ ì±„ìš© ìˆ˜ì§‘ ì¤‘...")
    all_jobs += scrape_incruit()

    print("ğŸ” ì¡ì½”ë¦¬ì•„ ì±„ìš© ìˆ˜ì§‘ ì¤‘...")
    all_jobs += scrape_jobkorea()

    print("ğŸ” ìœ„ë¹„í‹° ê³µëª¨ì „ ìˆ˜ì§‘ ì¤‘...")
    all_contests += scrape_wevity()

    print("ğŸ” ìº í¼ìŠ¤í”½ ê³µëª¨ì „ ìˆ˜ì§‘ ì¤‘...")
    all_contests += scrape_campuspick()

    # ğŸ”„ JSON ì—…ë°ì´íŠ¸
    data["lastUpdated"] = datetime.datetime.now().isoformat()
    data["jobs"] = all_jobs
    data["contests"] = all_contests

    save_data(data)

    print("âœ… ì™„ë£Œ! data.json ì—…ë°ì´íŠ¸ë¨.")
    print(f"   - ì±„ìš©: {len(all_jobs)}ê°œ")
    print(f"   - ê³µëª¨ì „: {len(all_contests)}ê°œ")

if __name__ == "__main__":
    main()


